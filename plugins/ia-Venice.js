import axios from "axios";

let handler = async (m, { conn, text, usedPrefix, command }) => {
  const query = text || (m.quoted && m.quoted.text);

  if (!query) {
    await conn.sendMessage(m.chat, {
      react: {
        text: "âŒ",
        key: m.key,
      },
    });
    return conn.reply(
      m.chat,
      "âŒ *ð™¸ð™½ð™¶ðšð™´ðš‚ð™° ðš„ð™½ð™° ð™¿ðšð™´ð™¶ðš„ð™½ðšƒð™°*\n\nâ–¸ ð™´ðš“ðšŽðš–ðš™ðš•ðš˜: ${usedPrefix}${command} Â¿ðš€ðšžÃ© ðšŽðšœ ðš•ðšŠ ð™¸ð™°?",
      m
    );
  }

  try {
    await conn.sendMessage(m.chat, {
      react: {
        text: "âš™ï¸",
        key: m.key,
      },
    });

    const { data } = await axios.request({
      method: "POST",
      url: "https://outerface.venice.ai/api/inference/chat",
      headers: {
        accept: "*/*",
        "content-type": "application/json",
        origin: "https://venice.ai",
        referer: "https://venice.ai/",
        "user-agent":
          "Mozilla/5.0 (Android 10; Mobile; rv:131.0) Gecko/131.0 Firefox/131.0",
        "x-venice-version": "interface@20250523.214528+393d253",
      },
      data: JSON.stringify({
        requestId: "mifinfinity",
        modelId: "dolphin-3.0-mistral-24b",
        prompt: [{ content: query, role: "user" }],
        systemPrompt: "",
        conversationType: "text",
        temperature: 0.8,
        webEnabled: true,
        topP: 0.9,
        isCharacter: false,
        clientProcessingTime: 15,
      }),
    });

    const chunks = data
      .split("\n")
      .filter((chunk) => chunk.trim() !== "")
      .map((chunk) => JSON.parse(chunk));

    const result = chunks.map((chunk) => chunk.content).join("");

    if (!result) {
      throw new Error("ð™½ðš˜ ðš‘ðšžðš‹ðš˜ ðš›ðšŽðšœðš™ðšžðšŽðšœðšðšŠ");
    }

    // Dividir si es muy largo
    const maxLength = 3000;
    if (result.length > maxLength) {
      const parts = [];
      for (let i = 0; i < result.length; i += maxLength) {
        parts.push(result.substring(i, i + maxLength));
      }

      // Primera parte
      await conn.reply(
        m.chat,
        `ðŸ¤– *ð™¸ð™½ðšƒð™´ð™»ð™¸ð™¶ð™´ð™½ð™²ð™¸ð™° ð™°ðšðšƒð™¸ð™µð™¸ð™²ð™¸ð™°ð™»:*\n\n${parts[0]}`,
        m
      );

      // Partes restantes
      for (let i = 1; i < parts.length; i++) {
        await conn.reply(m.chat, `${parts[i]}`, m);
      }
    } else {
      await conn.reply(m.chat, `ðŸ¤– *ð™¸ð™½ðšƒð™´ð™»ð™¸ð™¶ð™´ð™½ð™²ð™¸ð™° ð™°ðšðšƒð™¸ð™µð™¸ð™²ð™¸ð™°ð™»:*\n\n${result}`, m);
    }

    await conn.sendMessage(m.chat, {
      react: {
        text: "âœ…",
        key: m.key,
      },
    });
  } catch (err) {
    console.error("Error IA:", err.message);

    await conn.sendMessage(m.chat, {
      react: {
        text: "âŒ",
        key: m.key,
      },
    });

    await conn.reply(
      m.chat,
      `âŒ *ð™´ðšðšð™¾ðš*\n\nâ–¸ ${err.message || "ð™½ðš˜ ðšœðšŽ ðš™ðšžðšðš˜ ðš™ðš›ðš˜ðšŒðšŽðšœðšŠðš› ðš•ðšŠ ðš™ðšŽðšðš’ðšŒðš’Ã³ðš—"}`,
      m
    );
  }
};

handler.help = ["ia <pregunta>"];
handler.tags = ["ia"];
handler.command = ["ia", "ai", "inteligencia"];
handler.group = true;

export default handler;
